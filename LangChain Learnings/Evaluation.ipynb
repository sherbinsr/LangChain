{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc5672c9-eda4-42fb-8148-d6ddd4127249",
   "metadata": {},
   "source": [
    "# LangChain: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a507497-54b4-46d7-866a-07f02300ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from environment variables\n",
    "openai_key = os.getenv('API_KEY')\n",
    "os.environ[\"OPENAI_API_KEY\"]= openai_key\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25ece4e-6fbc-4121-bc31-558fba0d2ec0",
   "metadata": {},
   "source": [
    "## Create our QandA application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d687687-c90f-4f84-8542-e08e69ee091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef108ff0-23ea-4e0a-8f95-95ee72755b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'data.csv'\n",
    "loader = CSVLoader(file_path=file)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee32253-b13c-4931-a9d1-9a96a0d3d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Inmemory database\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2849ebf-f9a5-439b-a708-9c440e27f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature = 0.0, model=llm_model)\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=index.vectorstore.as_retriever(), \n",
    "    verbose=True,\n",
    "    chain_type_kwargs = {\n",
    "        \"document_separator\": \"<<<<>>>>>\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a18d59d-935a-4456-8f93-1d453782d997",
   "metadata": {},
   "source": [
    "## Coming up with test datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bf8188-ec0f-4dbf-ad39-32e7ac84b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a59426-43b1-4a01-9287-14242efc5dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7809749b-46cb-4a02-ba75-1709cac3bd67",
   "metadata": {},
   "source": [
    "## Hard-coded examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e4faa60-b3ea-4159-903d-d7edadb1e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"query\": \"Do the Cozy Comfort Pullover Set\\\n",
    "        have side pockets?\",\n",
    "        \"answer\": \"Yes\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What collection is the Ultra-Lofty \\\n",
    "        850 Stretch Down Hooded Jacket from?\",\n",
    "        \"answer\": \"The DownTek collection\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0350794-0ec8-4b80-8505-3150ddee98ba",
   "metadata": {},
   "source": [
    "## LLM-Generated example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e5afddc-35ed-4154-a768-b93329f0a705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAGenerateChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac45d021-2544-4f99-8d81-8ad48f74d51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_gen_chain = QAGenerateChain.from_llm(ChatOpenAI(model=llm_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f604cb-8a81-4cda-bbb4-84a1c9872905",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_examples = example_gen_chain.apply_and_parse(\n",
    "    [{\"doc\": t} for t in data[:5]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b907c5-b675-4793-8f3f-8ca97ed416f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b82d2c4-c10d-4f9e-8af3-9b141eff5c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b13191-66d2-46cf-93fe-1076af851662",
   "metadata": {},
   "source": [
    "## Combine examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c018670-add8-4bfc-9385-4a3a5d31e7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples += new_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d695f7f-3093-4b16-b972-f8f04c361271",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.run(examples[0][\"query\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbc7d91-ea5a-479c-a0af-c2c840e29c1b",
   "metadata": {},
   "source": [
    "## Manual Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a794a681-c501-4d99-88cc-ac3b9e4dc238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d016a4-73cd-445e-a995-1de0e75d7465",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.run(examples[0][\"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce8cd2-5ae3-4a8e-91f8-479796667113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off the debug mode\n",
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfafcfe3-f3f3-48dd-aa37-a1fcebc4b019",
   "metadata": {},
   "source": [
    "## LLM assisted evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd9085d-4c89-4024-a762-c109639356b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = qa.apply(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bfe7f848-38cf-4996-a58a-1185d1939f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAEvalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747430ed-3ba6-406b-92ed-bcd02a02aee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=llm_model)\n",
    "eval_chain = QAEvalChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c327c89d-2c13-4aad-9d14-b95b0b178855",
   "metadata": {},
   "outputs": [],
   "source": [
    "graded_outputs = eval_chain.evaluate(examples, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08db4b72-4ce5-4edd-a6d8-66b154cbc753",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, eg in enumerate(examples):\n",
    "    print(f\"Example {i}:\")\n",
    "    print(\"Question: \" + predictions[i]['query'])\n",
    "    print(\"Real Answer: \" + predictions[i]['answer'])\n",
    "    print(\"Predicted Answer: \" + predictions[i]['result'])\n",
    "    print(\"Predicted Grade: \" + graded_outputs[i]['text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f218c4e-726b-4b02-9faf-39407dc8c984",
   "metadata": {},
   "outputs": [],
   "source": [
    "graded_outputs[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
