{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39f7a9af-6cee-4bd9-b1d7-ad92e824cb31",
   "metadata": {},
   "source": [
    "# LangChain Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97b5185b-649f-4456-8602-ed486a33b9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from environment variables\n",
    "openai_key = os.getenv('API_KEY')\n",
    "os.environ[\"OPENAI_API_KEY\"]= openai_key\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74e44805-031d-4da1-90bb-72b309d5a0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67671819-0f5c-47db-b6d2-c8a2204dbaba",
   "metadata": {},
   "source": [
    "## Different types of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaac8285-7649-4dcb-a0a4-7f0d76e0cdcf",
   "metadata": {},
   "source": [
    "### ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bd71b56-99ad-4ff5-804b-3c01e5a41728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4eaa486d-b4f8-476c-be08-4928cbb26172",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0, model=llm_model)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4da85d-dacf-4820-9de3-412c996b2f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"Hey,My name is Andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710044b1-f40b-41b0-b55b-8c6a934aef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"what is 1+1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadf2b8-b2b3-43c3-b43d-cadbfc2ea43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What is my name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c26a2295-e9a7-4930-8bec-f3e4d2a7aca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# It prints all the chat history\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9a07d5c-f7b5-49f6-be80-9fba75fccd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': ''}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is another function to print all the chat history\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b89f96ab-eb64-49d3-9304-da2844393b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d82f5f4-1d72-4f5f-8aca-4605a490cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"}, \n",
    "                    {\"output\": \"What's up\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2abf8895-3034-49a1-8910-efaaad89100e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi\n",
      "AI: What's up\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "98b459ee-4aef-4130-b8da-216c015caa3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\"}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3acb4ea-9091-4212-aad3-8d07e234a563",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18c159b5-8494-4feb-94a4-31629c743007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ConversationBufferWindowMemory\n",
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6d3c9882-57fe-4240-9ad5-5c1b8caf43d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)   # K=1 represents that to remember only one conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2f22614e-07ca-4f8e-b68e-0a2ec0c4b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2239381f-cb67-4624-bd71-b798f2047fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## These type of memory only remembers recent chats\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f4babe-faf2-4a42-bc0a-1968022d8d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e61081-35c4-46df-ad08-6f20a1418553",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336afffb-cfae-42a6-958e-dac84c8ca36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94251d6-4989-42bd-be4b-14d2e9c705f8",
   "metadata": {},
   "source": [
    "## ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8fcee570-836e-444d-82be-d62d209a2d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\sherb\\anaconda3\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\sherb\\anaconda3\\lib\\site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\sherb\\anaconda3\\lib\\site-packages (from tiktoken) (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sherb\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sherb\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sherb\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sherb\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "177e4b0a-132e-4b9f-9265-ddf6e3265be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "66ceb746-1369-4386-b167-58b056474eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=50)\n",
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2d75f1e9-e146-41ff-acaf-d2c25a06fa5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: Amazing!\\nHuman: Backpropagation is what?\\nAI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686c69d6-45e5-433e-b978-bcb9cdc3dcb2",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7269c3de-c7fa-4759-bae4-701da14a6604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a52efac-893c-46ea-9a3f-e17d234a7e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3add6305-2e4c-4a52-8fe0-f92dd1180d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': ''}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
